# Projeto de An√°lise de Dados Pok√©dex - Sistemas de Banco de Dados 2

Este projeto tem como objetivo aplicar os conceitos de engenharia de dados para extrair, tratar e visualizar informa√ß√µes do dataset Pok√©dex. A metodologia utilizada √© a **Arquitetura Medalh√£o**, organizando o fluxo em tr√™s camadas: Bronze, Silver e Gold.

A ferramenta principal para a transforma√ß√£o dos dados ser√° o **PySpark**, para simular um ambiente de Big Data e praticar as opera√ß√µes distribu√≠das.


## üöÄ Estrutura do Projeto

O fluxo de dados seguir√° as seguintes etapas:

1.  **Camada Bronze:** Ingest√£o dos dados brutos.
2.  **Camada Silver:** Limpeza e transforma√ß√£o dos dados com PySpark.
3.  **Camada Gold:** Modelagem dos dados em um Data Warehouse.
4.  **Visualiza√ß√£o:** Cria√ß√£o de um dashboard interativo.


### ü•â Camada Bronze (Raw Data)

* **Objetivo:** Armazenar uma c√≥pia fiel e imut√°vel dos dados originais, exatamente como foram coletados da fonte.
* **Ferramentas:** Nenhuma (apenas download manual).
* **Entreg√°veis:**
    * O arquivo `pokedex.csv` original, localizado na pasta `/data/bronze/`.

### ü•à Camada Silver (Cleaned & Enriched Data)

* **Objetivo:** Transformar os dados brutos em informa√ß√µes confi√°veis e limpas. √â nesta camada que ocorre o processo de ETL (Extra√ß√£o, Transforma√ß√£o e Carga).
* **Ferramentas:** `Python`, `PySpark`, `Jupyter Notebook`.
* **Entreg√°veis:**
    * Um arquivo tratado (ex: em formato Parquet) na pasta `/data/silver/`.
    * O notebook `1_processamento_etl_pyspark.ipynb` com todo o c√≥digo de limpeza e tratamento, localizado na pasta `/notebooks/`.
    * Um **Dicion√°rio de Dados** que explica cada coluna da tabela tratada.

### ü•á Camada Gold (Business-Ready Data)

* **Objetivo:** Modelar os dados da camada Silver em um formato otimizado para an√°lises de neg√≥cio, geralmente um **Data Warehouse** com **Esquema Estrela**.
* **Ferramentas:** `Python`, `PySpark`, `PostgreSQL`, `Docker`.
* **Entreg√°veis:**
    * Um banco de dados PostgreSQL conteinerizado com a estrutura do Data Warehouse.
    * Scripts Python (`.py`) na pasta `/scripts/` que usam PySpark para carregar os dados nas tabelas **Fato** e **Dimens√£o**.
    * Um arquivo `docker-compose.yml` para iniciar o ambiente do banco de dados.

### üìä Camada de Visualiza√ß√£o

* **Objetivo:** Consumir os dados da Camada Gold para criar visualiza√ß√µes e dashboards que permitam extrair insights.
* **Ferramentas:** `Microsoft Power BI`.
* **Entreg√°veis:**
    * Um arquivo de dashboard (`.pbix`) conectado diretamente ao banco de dados PostgreSQL.
